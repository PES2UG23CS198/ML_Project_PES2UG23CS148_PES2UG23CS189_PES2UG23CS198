{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "F1Aoe6o--ZLZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import warnings\n",
        "import gradio as gr\n",
        "import pickle\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"STEP 1: LOADING AND EXPLORING DATA\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "df = pd.read_csv('/content/listings_clean_v1.csv')\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nFirst few rows:\\n{df.head()}\")\n",
        "print(f\"\\nData types:\\n{df.dtypes}\")\n",
        "print(f\"\\nMissing values:\\n{df.isnull().sum()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJSZh1jt-iyD",
        "outputId": "13346191-dcb5-4380-a20f-35d78a3eccd0"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "STEP 1: LOADING AND EXPLORING DATA\n",
            "============================================================\n",
            "Dataset shape: (18539, 21)\n",
            "\n",
            "First few rows:\n",
            "      id                                               name  host_id  \\\n",
            "0  10803             Room in Deco Apartment, Brunswick East    38901   \n",
            "1  43429                 Tranquil Javanese Studio and Pond!   189684   \n",
            "2  44082                      Queen Room in Beautiful House   193031   \n",
            "3  47100  Cosy, cute comfortable little home in top loca...   212071   \n",
            "4  51592                   Central City Warehouse Apartment   190879   \n",
            "\n",
            "  host_name  neighbourhood_group neighbourhood   latitude   longitude  \\\n",
            "0   Lindsay                  NaN      Moreland -37.766060  144.979510   \n",
            "1     Allan                  NaN        Monash -37.899830  145.115790   \n",
            "2     Vicki                  NaN     Frankston -38.147680  145.143640   \n",
            "3     Loren                  NaN         Yarra -37.818371  145.005005   \n",
            "4  Michelle                  NaN     Melbourne -37.812660  144.963130   \n",
            "\n",
            "         room_type  price  ...  number_of_reviews  last_review  \\\n",
            "0     Private room   54.0  ...                204   2025-04-23   \n",
            "1  Entire home/apt  128.0  ...                269   2025-06-04   \n",
            "2     Private room   79.0  ...                 65   2025-04-06   \n",
            "3  Entire home/apt  116.0  ...                180   2025-01-08   \n",
            "4  Entire home/apt  257.0  ...                497   2025-05-24   \n",
            "\n",
            "  reviews_per_month  calculated_host_listings_count  availability_365  \\\n",
            "0              1.35                               1               148   \n",
            "1              1.52                               3               165   \n",
            "2              0.37                               8               127   \n",
            "3              1.00                               1                16   \n",
            "4              2.85                               1               193   \n",
            "\n",
            "   number_of_reviews_ltm  license  log_price  last_review_year  \\\n",
            "0                     14      NaN   4.007333            2025.0   \n",
            "1                     10      NaN   4.859812            2025.0   \n",
            "2                      6      NaN   4.382027            2025.0   \n",
            "3                      1      NaN   4.762174            2025.0   \n",
            "4                     52      NaN   5.552960            2025.0   \n",
            "\n",
            "   last_review_month  \n",
            "0                4.0  \n",
            "1                6.0  \n",
            "2                4.0  \n",
            "3                1.0  \n",
            "4                5.0  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "\n",
            "Data types:\n",
            "id                                  int64\n",
            "name                               object\n",
            "host_id                             int64\n",
            "host_name                          object\n",
            "neighbourhood_group               float64\n",
            "neighbourhood                      object\n",
            "latitude                          float64\n",
            "longitude                         float64\n",
            "room_type                          object\n",
            "price                             float64\n",
            "minimum_nights                      int64\n",
            "number_of_reviews                   int64\n",
            "last_review                        object\n",
            "reviews_per_month                 float64\n",
            "calculated_host_listings_count      int64\n",
            "availability_365                    int64\n",
            "number_of_reviews_ltm               int64\n",
            "license                           float64\n",
            "log_price                         float64\n",
            "last_review_year                  float64\n",
            "last_review_month                 float64\n",
            "dtype: object\n",
            "\n",
            "Missing values:\n",
            "id                                    0\n",
            "name                                  0\n",
            "host_id                               0\n",
            "host_name                             3\n",
            "neighbourhood_group               18539\n",
            "neighbourhood                         0\n",
            "latitude                              0\n",
            "longitude                             0\n",
            "room_type                             0\n",
            "price                                 0\n",
            "minimum_nights                        0\n",
            "number_of_reviews                     0\n",
            "last_review                        2733\n",
            "reviews_per_month                  2733\n",
            "calculated_host_listings_count        0\n",
            "availability_365                      0\n",
            "number_of_reviews_ltm                 0\n",
            "license                           18539\n",
            "log_price                             0\n",
            "last_review_year                   2733\n",
            "last_review_month                  2733\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 2: DATA CLEANING\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "df_clean = df.copy()\n",
        "\n",
        "# Drop rows where price (target) is missing\n",
        "if 'price' in df_clean.columns:\n",
        "    df_clean = df_clean.dropna(subset=['price'])\n",
        "\n",
        "# For numerical columns: fill with median\n",
        "numerical_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
        "for col in numerical_cols:\n",
        "    if df_clean[col].isnull().sum() > 0:\n",
        "        median_val = df_clean[col].median()\n",
        "        if pd.isna(median_val):\n",
        "            df_clean[col].fillna(0, inplace=True)\n",
        "        else:\n",
        "            df_clean[col].fillna(median_val, inplace=True)\n",
        "\n",
        "# For categorical columns: fill with mode or 'Unknown'\n",
        "categorical_cols = df_clean.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    if df_clean[col].isnull().sum() > 0:\n",
        "        mode_val = df_clean[col].mode()\n",
        "        if len(mode_val) > 0:\n",
        "            df_clean[col].fillna(mode_val[0], inplace=True)\n",
        "        else:\n",
        "            df_clean[col].fillna('Unknown', inplace=True)\n",
        "\n",
        "# Drop any remaining rows with NaN\n",
        "df_clean = df_clean.dropna()\n",
        "\n",
        "print(\"Missing values after cleaning:\")\n",
        "print(f\"Total NaN values: {df_clean.isnull().sum().sum()}\")\n",
        "print(f\"Dataset shape: {df_clean.shape}\")\n",
        "\n",
        "# Remove outliers using IQR method\n",
        "print(\"\\nRemoving outliers...\")\n",
        "Q1 = df_clean['price'].quantile(0.25)\n",
        "Q3 = df_clean['price'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "df_clean = df_clean[(df_clean['price'] >= Q1 - 1.5 * IQR) &\n",
        "                     (df_clean['price'] <= Q3 + 1.5 * IQR)]\n",
        "\n",
        "# Final check for NaN\n",
        "df_clean = df_clean.dropna()\n",
        "print(f\"Dataset shape after outlier removal: {df_clean.shape}\")\n",
        "print(f\"Final NaN check: {df_clean.isnull().sum().sum()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqAU6CZSB5zH",
        "outputId": "1a6e44ca-8d16-42c8-98f9-d61488ba6a54"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 2: DATA CLEANING\n",
            "============================================================\n",
            "Missing values after cleaning:\n",
            "Total NaN values: 0\n",
            "Dataset shape: (18539, 21)\n",
            "\n",
            "Removing outliers...\n",
            "Dataset shape after outlier removal: (17106, 21)\n",
            "Final NaN check: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 3: FEATURE ENGINEERING\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "X = df_clean.drop('price', axis=1)\n",
        "y = df_clean['price']\n",
        "\n",
        "# Remove non-numeric and problematic columns\n",
        "for col in X.columns:\n",
        "    if X[col].dtype == 'object':\n",
        "        # Try to encode categorical, skip if too many unique values\n",
        "        if X[col].nunique() > 100:\n",
        "            X = X.drop(col, axis=1)\n",
        "\n",
        "# Encode categorical variables\n",
        "le_dict = {}\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "for col in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    X[col] = le.fit_transform(X[col].astype(str))\n",
        "    le_dict[col] = le\n",
        "\n",
        "# Final NaN check in X\n",
        "X = X.replace([np.inf, -np.inf], np.nan)\n",
        "X = X.dropna()\n",
        "y = y[X.index]\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "print(f\"Final NaN in X: {X.isnull().sum().sum()}\")\n",
        "print(f\"Final NaN in y: {y.isnull().sum()}\")\n",
        "print(f\"Encoded categorical features: {list(categorical_features)}\")\n",
        "\n",
        "# Store feature names and min-max for UI\n",
        "feature_names = X.columns.tolist()\n",
        "feature_ranges = {col: (X[col].min(), X[col].max()) for col in feature_names}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARMmGhN6CBLd",
        "outputId": "1c065c35-b406-4903-cde6-30e966d21bd2"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 3: FEATURE ENGINEERING\n",
            "============================================================\n",
            "Features shape: (17106, 17)\n",
            "Target shape: (17106,)\n",
            "Final NaN in X: 0\n",
            "Final NaN in y: 0\n",
            "Encoded categorical features: ['neighbourhood', 'room_type']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 4: CREATING VISUALIZATIONS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "axes[0, 0].hist(y, bins=50, color='skyblue', edgecolor='black')\n",
        "axes[0, 0].set_title('Price Distribution', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Price')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "\n",
        "corr_matrix = X.corr()\n",
        "top_features = corr_matrix.iloc[:, 0].abs().nlargest(6).index\n",
        "sns.heatmap(X[top_features].corr(), annot=True, cmap='coolwarm', ax=axes[0, 1], fmt='.2f')\n",
        "axes[0, 1].set_title('Feature Correlation Matrix', fontsize=12, fontweight='bold')\n",
        "\n",
        "feature_corr = X.corrwith(y).abs().sort_values(ascending=False).head(10)\n",
        "axes[1, 0].barh(range(len(feature_corr)), feature_corr.values, color='green')\n",
        "axes[1, 0].set_yticks(range(len(feature_corr)))\n",
        "axes[1, 0].set_yticklabels(feature_corr.index)\n",
        "axes[1, 0].set_title('Top 10 Feature Correlations with Price', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Absolute Correlation')\n",
        "\n",
        "axes[1, 1].text(0.5, 0.5, 'Feature Analysis Complete',\n",
        "                ha='center', va='center', transform=axes[1, 1].transAxes, fontsize=14)\n",
        "axes[1, 1].set_title('Dataset Overview', fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('01_exploratory_analysis.png', dpi=300, bbox_inches='tight')\n",
        "print(\"‚úì Saved: 01_exploratory_analysis.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COMZs1diCRuG",
        "outputId": "98497df7-6298-41a7-f693-85939da29024"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 4: CREATING VISUALIZATIONS\n",
            "============================================================\n",
            "‚úì Saved: 01_exploratory_analysis.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 5: TRAIN-TEST SPLIT & FEATURE SCALING\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(f\"Training set size: {X_train.shape}\")\n",
        "print(f\"Test set size: {X_test.shape}\")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "print(\"Features scaled using StandardScaler\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1oi9dXxDK2p",
        "outputId": "b85fe374-412b-4e63-9785-56f442584a66"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 5: TRAIN-TEST SPLIT & FEATURE SCALING\n",
            "============================================================\n",
            "Training set size: (13684, 17)\n",
            "Test set size: (3422, 17)\n",
            "Features scaled using StandardScaler\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 6: BUILDING AND TRAINING MODELS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge (Œ±=100.0)': Ridge(alpha=100.0),\n",
        "    'Lasso (Œ±=1.0)': Lasso(alpha=1.0),\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=150, max_depth=10, min_samples_split=5, min_samples_leaf=2, max_features='sqrt', random_state=42, n_jobs=-1),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=200, learning_rate=0.01, max_depth=3, min_samples_leaf=5, subsample=0.8, validation_fraction=0.1, n_iter_no_change=10, random_state=42)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    results[name] = {'model': model, 'rmse': rmse, 'mae': mae, 'r2': r2, 'pred': y_pred}\n",
        "\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"  RMSE: {rmse:.4f}\")\n",
        "    print(f\"  MAE:  {mae:.4f}\")\n",
        "    print(f\"  R¬≤:   {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhPdnXhwCak-",
        "outputId": "f5620d0a-ce74-477d-9025-020a16fe12a6"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 6: BUILDING AND TRAINING MODELS\n",
            "============================================================\n",
            "\n",
            "Linear Regression:\n",
            "  RMSE: 23.2691\n",
            "  MAE:  16.7375\n",
            "  R¬≤:   0.9217\n",
            "\n",
            "Ridge (Œ±=100.0):\n",
            "  RMSE: 23.3189\n",
            "  MAE:  16.7813\n",
            "  R¬≤:   0.9213\n",
            "\n",
            "Lasso (Œ±=1.0):\n",
            "  RMSE: 23.4795\n",
            "  MAE:  17.0245\n",
            "  R¬≤:   0.9203\n",
            "\n",
            "Random Forest:\n",
            "  RMSE: 14.3543\n",
            "  MAE:  9.3705\n",
            "  R¬≤:   0.9702\n",
            "\n",
            "Gradient Boosting:\n",
            "  RMSE: 11.8810\n",
            "  MAE:  9.1136\n",
            "  R¬≤:   0.9796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 8: MODEL COMPARISON\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "comparison_data = {\n",
        "    'Model': list(results.keys()),\n",
        "    'RMSE': [f\"{results[m]['rmse']:.4f}\" for m in results.keys()],\n",
        "    'MAE': [f\"{results[m]['mae']:.4f}\" for m in results.keys()],\n",
        "    'R¬≤ Score': [f\"{results[m]['r2']:.4f}\" for m in results.keys()]\n",
        "}\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(\"\\n\" + comparison_df.to_string(index=False))\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "model_names = list(results.keys())\n",
        "rmse_vals = [results[m]['rmse'] for m in model_names]\n",
        "r2_vals = [results[m]['r2'] for m in model_names]\n",
        "\n",
        "sorted_idx = sorted(range(len(r2_vals)), key=lambda i: r2_vals[i], reverse=True)\n",
        "sorted_names = [model_names[i] for i in sorted_idx]\n",
        "sorted_rmse = [rmse_vals[i] for i in sorted_idx]\n",
        "sorted_r2 = [r2_vals[i] for i in sorted_idx]\n",
        "\n",
        "axes[0].barh(sorted_names, sorted_rmse, color='coral')\n",
        "axes[0].set_xlabel('RMSE (Lower is Better)', fontweight='bold')\n",
        "axes[0].set_title('Model RMSE Comparison', fontsize=12, fontweight='bold')\n",
        "axes[0].invert_yaxis()\n",
        "\n",
        "axes[1].barh(sorted_names, sorted_r2, color='lightgreen')\n",
        "axes[1].set_xlabel('R¬≤ Score (Higher is Better)', fontweight='bold')\n",
        "axes[1].set_title('Model R¬≤ Score Comparison', fontsize=12, fontweight='bold')\n",
        "axes[1].invert_yaxis()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('02_model_comparison.png', dpi=300, bbox_inches='tight')\n",
        "print(\"\\n‚úì Saved: 02_model_comparison.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c3og3ZgKehp",
        "outputId": "b0352e21-80d7-4e35-cd69-51dcb8dccd1e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 8: MODEL COMPARISON\n",
            "============================================================\n",
            "\n",
            "            Model    RMSE     MAE R¬≤ Score\n",
            "Linear Regression 23.2691 16.7375   0.9217\n",
            "  Ridge (Œ±=100.0) 23.3189 16.7813   0.9213\n",
            "    Lasso (Œ±=1.0) 23.4795 17.0245   0.9203\n",
            "    Decision Tree  3.1935  2.6970   0.9985\n",
            "    Random Forest 14.3543  9.3705   0.9702\n",
            "Gradient Boosting 11.8810  9.1136   0.9796\n",
            "\n",
            "‚úì Saved: 02_model_comparison.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 9: BEST MODEL ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "best_model_name = comparison_df.iloc[0]['Model']\n",
        "best_model = results[best_model_name]['model']\n",
        "best_pred = results[best_model_name]['pred']\n",
        "best_rmse = results[best_model_name]['rmse']\n",
        "best_r2 = results[best_model_name]['r2']\n",
        "\n",
        "print(f\"\\nBest Model: {best_model_name}\")\n",
        "print(f\"RMSE: {best_rmse:.4f}\")\n",
        "print(f\"R¬≤: {best_r2:.4f}\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "axes[0].scatter(y_test, best_pred, alpha=0.5, color='blue')\n",
        "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "axes[0].set_xlabel('Actual Price', fontweight='bold')\n",
        "axes[0].set_ylabel('Predicted Price', fontweight='bold')\n",
        "axes[0].set_title('Actual vs Predicted Prices', fontsize=12, fontweight='bold')\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "residuals = y_test - best_pred\n",
        "axes[1].scatter(best_pred, residuals, alpha=0.5, color='green')\n",
        "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
        "axes[1].set_xlabel('Predicted Price', fontweight='bold')\n",
        "axes[1].set_ylabel('Residuals', fontweight='bold')\n",
        "axes[1].set_title('Residuals Plot', fontsize=12, fontweight='bold')\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('03_best_model_analysis.png', dpi=300, bbox_inches='tight')\n",
        "print(\"‚úì Saved: 03_best_model_analysis.png\")\n",
        "plt.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT9tdw_ZKue_",
        "outputId": "e6c77b5a-36ee-4edd-f6f9-dbc89a4e522d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 9: BEST MODEL ANALYSIS\n",
            "============================================================\n",
            "\n",
            "Best Model: Linear Regression\n",
            "RMSE: 23.2691\n",
            "R¬≤: 0.9217\n",
            "‚úì Saved: 03_best_model_analysis.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 10: CROSS-VALIDATION & OVERFITTING ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "cv_scores = cross_val_score(best_model, X_train_scaled, y_train,\n",
        "                            cv=5, scoring='r2')\n",
        "print(f\"Cross-validation R¬≤ scores: {cv_scores}\")\n",
        "print(f\"Mean CV R¬≤: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
        "\n",
        "# Calculate overfitting metric\n",
        "train_pred = best_model.predict(X_train_scaled)\n",
        "train_r2 = r2_score(y_train, train_pred)\n",
        "test_r2 = best_r2\n",
        "\n",
        "print(f\"\\n--- Overfitting Check ---\")\n",
        "print(f\"Training R¬≤: {train_r2:.4f}\")\n",
        "print(f\"Testing R¬≤:  {test_r2:.4f}\")\n",
        "print(f\"Difference:  {(train_r2 - test_r2):.4f} (should be < 0.05)\")\n",
        "\n",
        "if (train_r2 - test_r2) < 0.05:\n",
        "    print(\"‚úì Model is NOT overfitting - Good generalization!\")\n",
        "else:\n",
        "    print(\"‚ö† Model shows signs of overfitting\")\n",
        "\n",
        "# ============= FINAL SUMMARY =============\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FINAL SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\n‚úì Best Model: {best_model_name}\")\n",
        "print(f\"‚úì Test RMSE: {best_rmse:.4f}\")\n",
        "print(f\"‚úì Test R¬≤ Score: {best_r2:.4f}\")\n",
        "print(f\"‚úì Cross-validation R¬≤: {cv_scores.mean():.4f}\")\n",
        "print(f\"\\nDataset size: {len(df_clean)}\")\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Testing samples: {len(X_test)}\")\n",
        "print(f\"Number of features: {X.shape[1]}\")\n",
        "\n",
        "# Save model and scaler\n",
        "pickle.dump(best_model, open('best_model.pkl', 'wb'))\n",
        "pickle.dump(scaler, open('scaler.pkl', 'wb'))\n",
        "pickle.dump(feature_names, open('feature_names.pkl', 'wb'))\n",
        "pickle.dump(le_dict, open('le_dict.pkl', 'wb'))\n",
        "print(\"\\n‚úì Models saved for Gradio UI\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFlmcW2SK64C",
        "outputId": "15972fbf-82ff-4543-f2ec-12b9974e4e7a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 10: CROSS-VALIDATION & OVERFITTING ANALYSIS\n",
            "============================================================\n",
            "Cross-validation R¬≤ scores: [0.91633017 0.92097101 0.9210453  0.91908777 0.91804384]\n",
            "Mean CV R¬≤: 0.9191 (+/- 0.0018)\n",
            "\n",
            "--- Overfitting Check ---\n",
            "Training R¬≤: 0.9194\n",
            "Testing R¬≤:  0.9217\n",
            "Difference:  -0.0022 (should be < 0.05)\n",
            "‚úì Model is NOT overfitting - Good generalization!\n",
            "\n",
            "============================================================\n",
            "FINAL SUMMARY\n",
            "============================================================\n",
            "\n",
            "‚úì Best Model: Linear Regression\n",
            "‚úì Test RMSE: 23.2691\n",
            "‚úì Test R¬≤ Score: 0.9217\n",
            "‚úì Cross-validation R¬≤: 0.9191\n",
            "\n",
            "Dataset size: 17106\n",
            "Training samples: 13684\n",
            "Testing samples: 3422\n",
            "Number of features: 17\n",
            "\n",
            "‚úì Models saved for Gradio UI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 11: LAUNCHING GRADIO UI\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def predict_price(*args):\n",
        "    \"\"\"\n",
        "    Predict Airbnb price based on input features\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create input array from user inputs\n",
        "        input_data = np.array(list(args)).reshape(1, -1)\n",
        "\n",
        "        # Scale the input\n",
        "        input_scaled = scaler.transform(input_data)\n",
        "\n",
        "        # Make prediction\n",
        "        predicted_price = best_model.predict(input_scaled)[0]\n",
        "\n",
        "        # Format output\n",
        "        result = f\"\"\"\n",
        "        <div style='text-align: center; padding: 20px; background-color: #f0f0f0; border-radius: 10px;'>\n",
        "            <h2 style='color: #2c3e50; margin: 0;'>Predicted Airbnb Price</h2>\n",
        "            <p style='font-size: 14px; color: #7f8c8d; margin-top: 5px;'>{best_model_name}</p>\n",
        "            <h1 style='color: #27ae60; font-size: 48px; margin: 20px 0;'>${predicted_price:,.2f}</h1>\n",
        "            <p style='color: #95a5a6; font-size: 12px;'>\n",
        "                Model Accuracy (R¬≤): {best_r2:.2%} | RMSE: ${best_rmse:.2f}\n",
        "            </p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return f\"<div style='color: red; padding: 20px;'><h3>Error:</h3><p>{str(e)}</p></div>\"\n",
        "\n",
        "# Create Gradio input components\n",
        "inputs = []\n",
        "for i, feature in enumerate(feature_names):\n",
        "    min_val, max_val = feature_ranges[feature]\n",
        "    inputs.append(\n",
        "        gr.Slider(\n",
        "            minimum=min_val,\n",
        "            maximum=max_val,\n",
        "            value=(min_val + max_val) / 2,\n",
        "            label=f\"{feature} ({min_val:.0f} - {max_val:.0f})\",\n",
        "            step=0.1\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Create Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=predict_price,\n",
        "    inputs=inputs,\n",
        "    outputs=gr.HTML(),\n",
        "    title=\"üè† Airbnb Rental Price Predictor\",\n",
        "    description=f\"\"\"\n",
        "    <div style='text-align: center; padding: 20px;'>\n",
        "        <h3>Predict Airbnb listing prices using Machine Learning</h3>\n",
        "        <p><strong>Model:</strong> {best_model_name}</p>\n",
        "        <p><strong>Accuracy (R¬≤ Score):</strong> {best_r2:.2%}</p>\n",
        "        <p><strong>RMSE:</strong> ${best_rmse:.2f}</p>\n",
        "        <p style='color: #7f8c8d;'>Adjust the sliders below to predict rental prices based on property features</p>\n",
        "    </div>\n",
        "    \"\"\",\n",
        "    theme=gr.themes.Soft(),\n",
        "    examples=[\n",
        "        [(feature_ranges[f][0] + feature_ranges[f][1]) / 2 for f in feature_names],\n",
        "        [(feature_ranges[f][1] * 0.75) for f in feature_names],\n",
        "        [(feature_ranges[f][1] * 0.25) for f in feature_names],\n",
        "    ]\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"üöÄ Launching Gradio UI...\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"\\nüìä All visualizations saved:\")\n",
        "    print(\"  ‚úì 01_exploratory_analysis.png\")\n",
        "    print(\"  ‚úì 02_model_comparison.png\")\n",
        "    print(\"  ‚úì 03_best_model_analysis.png\")\n",
        "    print(\"\\nüíæ Model artifacts saved:\")\n",
        "    print(\"  ‚úì best_model.pkl\")\n",
        "    print(\"  ‚úì scaler.pkl\")\n",
        "    print(\"  ‚úì feature_names.pkl\")\n",
        "    print(\"  ‚úì le_dict.pkl\")\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "    interface.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 975
        },
        "id": "cg6jMFjJLEvr",
        "outputId": "6efc08df-54c9-4057-c20d-981b6af370d3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 11: LAUNCHING GRADIO UI\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "üöÄ Launching Gradio UI...\n",
            "============================================================\n",
            "\n",
            "üìä All visualizations saved:\n",
            "  ‚úì 01_exploratory_analysis.png\n",
            "  ‚úì 02_model_comparison.png\n",
            "  ‚úì 03_best_model_analysis.png\n",
            "\n",
            "üíæ Model artifacts saved:\n",
            "  ‚úì best_model.pkl\n",
            "  ‚úì scaler.pkl\n",
            "  ‚úì feature_names.pkl\n",
            "  ‚úì le_dict.pkl\n",
            "\n",
            "============================================================\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://34d07d54f6be570b9a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://34d07d54f6be570b9a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}